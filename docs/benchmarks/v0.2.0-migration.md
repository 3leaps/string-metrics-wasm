# Performance Benchmarks: v0.1.0 (strsim) vs v0.2.0 (rapidfuzz)

**Date**: 2025-10-29 **Platform**: darwin-arm64 **Node.js**: v22.19.0 **Iterations**: 10,000 per
test (after 100 warmup)

## Executive Summary

Migration from strsim-rs to rapidfuzz-rs delivers **1.9x to 2.6x performance improvement** across
all core functions with minimal cold-init overhead.

### Key Findings

- ✅ **Hot loop performance**: +93% to +159% faster (all functions)
- ⚠️ **Cold init**: +76 µs slower (116 µs vs 40 µs, still sub-millisecond)
- ✅ **Bundle size**: +29% (225 KB vs 174 KB, within tolerance)
- ✅ **API compatibility**: 100% behavioral equivalence (47/47 tests passing)

## Cold Init Performance

| Version            | Average   | Min     | Max         | Change   |
| ------------------ | --------- | ------- | ----------- | -------- |
| v0.1.0 (strsim)    | 40.30 µs  | 0.75 µs | 338.96 µs   | baseline |
| v0.2.0 (rapidfuzz) | 116.21 µs | 0.75 µs | 1,098.00 µs | +188%    |

**Analysis**: Cold init is ~76 µs slower with rapidfuzz due to larger module size, but remains
sub-millisecond and is negligible for typical server/CLI usage patterns.

## Hot Loop Performance (Throughput)

All measurements are sustained throughput after warmup (120,000 operations total per function).

### Levenshtein Distance

| Version | Throughput    | Latency | Change              |
| ------- | ------------- | ------- | ------------------- |
| v0.1.0  | 1.54M ops/sec | 0.65 µs | baseline            |
| v0.2.0  | 3.27M ops/sec | 0.31 µs | **+112% faster** ✅ |

### Normalized Levenshtein

| Version | Throughput    | Latency | Change              |
| ------- | ------------- | ------- | ------------------- |
| v0.1.0  | 1.61M ops/sec | 0.62 µs | baseline            |
| v0.2.0  | 4.17M ops/sec | 0.24 µs | **+159% faster** ✅ |

### Damerau-Levenshtein Distance

| Version | Throughput      | Latency | Change              |
| ------- | --------------- | ------- | ------------------- |
| v0.1.0  | 773.44K ops/sec | 1.29 µs | baseline            |
| v0.2.0  | 1.63M ops/sec   | 0.61 µs | **+111% faster** ✅ |

### Normalized Damerau-Levenshtein

| Version | Throughput      | Latency | Change              |
| ------- | --------------- | ------- | ------------------- |
| v0.1.0  | 780.86K ops/sec | 1.28 µs | baseline            |
| v0.2.0  | 1.65M ops/sec   | 0.61 µs | **+111% faster** ✅ |

### Jaro Similarity

| Version | Throughput    | Latency | Change             |
| ------- | ------------- | ------- | ------------------ |
| v0.1.0  | 1.92M ops/sec | 0.52 µs | baseline           |
| v0.2.0  | 3.72M ops/sec | 0.27 µs | **+94% faster** ✅ |

### Jaro-Winkler Similarity

| Version | Throughput    | Latency | Change             |
| ------- | ------------- | ------- | ------------------ |
| v0.1.0  | 1.93M ops/sec | 0.52 µs | baseline           |
| v0.2.0  | 3.72M ops/sec | 0.27 µs | **+93% faster** ✅ |

## Performance Summary

| Function                       | v0.1.0 Throughput | v0.2.0 Throughput | Improvement |
| ------------------------------ | ----------------- | ----------------- | ----------- |
| levenshtein                    | 1.54M ops/sec     | 3.27M ops/sec     | **+2.1x**   |
| normalized_levenshtein         | 1.61M ops/sec     | 4.17M ops/sec     | **+2.6x**   |
| damerau_levenshtein            | 773K ops/sec      | 1.63M ops/sec     | **+2.1x**   |
| normalized_damerau_levenshtein | 781K ops/sec      | 1.65M ops/sec     | **+2.1x**   |
| jaro                           | 1.92M ops/sec     | 3.72M ops/sec     | **+1.9x**   |
| jaro_winkler                   | 1.93M ops/sec     | 3.72M ops/sec     | **+1.9x**   |

## Trade-offs Analysis

### Benefits

- **Massive performance gains**: All functions 1.9x–2.6x faster
- **Ecosystem alignment**: Matches pyfulmen/gofulmen semantics
- **Feature expansion**: Unlocks token-based metrics (Phase 1)
- **Active maintenance**: rapidfuzz has SIMD optimizations and regular updates

### Costs

- **Bundle size**: +51 KB (+29%) – within +50% tolerance
- **Cold init**: +76 µs – negligible for server/CLI workloads
- **Breaking change**: Requires v0.2.0 semantic version bump

## Recommendations

1. ✅ **Proceed with v0.2.0 release**: Performance gains far outweigh bundle size cost
2. ✅ **Document migration**: Highlight performance improvements in release notes
3. ✅ **Monitor Phase 1**: Track bundle size as token-based metrics are added
4. ⏭️ **Consider benchmarking**: Add continuous benchmarking in CI for regression detection

## Test Methodology

- **Platform**: macOS (darwin-arm64), Node.js v22.19.0
- **Warmup**: 100 iterations per function to stabilize JIT
- **Measurement**: 10,000 iterations × 12 test pairs = 120,000 ops per function
- **Test data**: Mix of short (3-8 chars), medium (8-16 chars), long (30-45 chars), and Unicode
  strings
- **Timing**: `performance.now()` with microsecond precision

## Reproducibility

To reproduce these benchmarks:

```bash
# v0.2.0-dev (rapidfuzz)
npm run build
npm run bench

# v0.1.0 (strsim) - for comparison
git checkout v0.1.0
npm run build
npm run bench
git checkout main
```

## Conclusion

The migration to rapidfuzz-rs delivers **exceptional performance gains** (1.9x–2.6x) with acceptable
bundle size growth (+29%). The slight cold-init overhead (76 µs) is negligible for real-world usage.

**Recommendation**: ✅ Approve for v0.2.0 release
